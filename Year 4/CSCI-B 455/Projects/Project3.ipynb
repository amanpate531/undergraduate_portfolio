{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AF5XG_EqKRGR"
      },
      "source": [
        "#Project 3 - Comparing Deep Neural Network Architectures to Improve Image Multi-Class Classification\n",
        "\n",
        "Aman Patel\n",
        "\n",
        "CSCI-B 455\n",
        "\n",
        "March 28, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwD2ZWBaKkTi"
      },
      "source": [
        "# **Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BrKzcJvCKoWi"
      },
      "source": [
        "## Problem Statement\n",
        "The goal for this project was to create a baseline Deep Neural Network to classify images from the CIFAR-10 dataset, then create two additional DNNs that improve upon the architecture of the baseline."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6T4JaxQsLMjw"
      },
      "source": [
        "## Data\n",
        "\n",
        "The dataset used for this project was collected from the University of Toronto Computer Science Department. It contains 60000 color images of objects and animals, partitioned into 50000 training images and 10000 test images. The data can be found at \n",
        "https://www.cs.toronto.edu/~kriz/cifar.html\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DUIdqfdLxTW"
      },
      "source": [
        "## Model Parameters\n",
        "\n",
        "For the baseline model (Model1), the input matrix of 32x32 pixels was flattened into a vector of 1024 pixels. To demonstrate the effects of overcompression, the first hidden layer contained only five neurons. The data was then expanded using a hidden layer of 100 neurons, then compressed to ten neurons in the output layer. This corresponds with the number of possible class labels. Each hidden layer used a sigmoid activation function, while the output layer used a softmax function to select the class with the highest probability.\n",
        "\n",
        "For the first improved model (Model2), the input matrix was again flattened. Instead of using a bottleneck layer to compress the data rapidly, the data was gradually compressed. This was done by using hidden layers of 200 neurons and 50 neurons, and an output layer of ten neurons. This model also used a sigmoid activation function for the hidden layers and the softmax function for the output layer.\n",
        "\n",
        "For the second improved model (Model3), the architecture is similar to that of Model2, but the activation function for the hidden layers was changed. By using the ReLU activation function instead of sigmoid, the gradient can be maintained. This leads to improved adaptibility and faster learning.\n",
        "\n",
        "The loss function and optimizer were consistent for all three models. They were chosen because of their versatility and their compatibility with my code."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_-832TcPKkp"
      },
      "source": [
        "# **Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "iE66lDWnL0wo",
        "outputId": "c1c228a8-d611-455e-ba31-6c31b410e969"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.layers.experimental.preprocessing import Rescaling\n",
        "import cv2\n",
        "\n",
        "# baseline model\n",
        "class Model1(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model1, self).__init__()\n",
        "    # flattens the input matrix into a vector\n",
        "    self.flatten_layer = tf.keras.layers.Flatten(input_shape = (32, 32))\n",
        "    # hidden layers - first layer is a bottleneck layer\n",
        "    self.layer1 = tf.keras.layers.Dense(5, activation = tf.nn.sigmoid)\n",
        "    self.layer2 = tf.keras.layers.Dense(100, activation = tf.nn.sigmoid)\n",
        "    # output layer\n",
        "    self.layer3 = tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "  \n",
        "  # forward propagation of input matrix\n",
        "  def call(self, inputs):\n",
        "    flattened = self.flatten_layer(inputs)\n",
        "    hidden1 = self.layer1(flattened)\n",
        "    hidden2 = self.layer2(hidden1)\n",
        "    return self.layer3(hidden2)\n",
        "\n",
        "# first improved model\n",
        "class Model2(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model2, self).__init__()\n",
        "    # flattens the input matrix into a vector\n",
        "    self.flatten_layer = tf.keras.layers.Flatten(input_shape = (32, 32))\n",
        "    # hidden layers - number of hidden neurons changed to minimize overcompression\n",
        "    self.layer1 = tf.keras.layers.Dense(200, activation = tf.nn.sigmoid)\n",
        "    self.layer2 = tf.keras.layers.Dense(50, activation = tf.nn.sigmoid)\n",
        "    # output layer\n",
        "    self.layer3 = tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "  \n",
        "  # forward propagation of input matrix\n",
        "  def call(self, inputs):\n",
        "    flattened = self.flatten_layer(inputs)\n",
        "    hidden1 = self.layer1(flattened)\n",
        "    hidden2 = self.layer2(hidden1)\n",
        "    return self.layer3(hidden2)\n",
        "\n",
        "class Model3(tf.keras.Model):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(Model3, self).__init__()\n",
        "    # flattens the input matrix into a vector\n",
        "    self.flatten_layer = tf.keras.layers.Flatten(input_shape = (32, 32))\n",
        "    # hidden layers - activation functions changed to ReLU to maintain gradient\n",
        "    self.layer1 = tf.keras.layers.Dense(200, activation = tf.nn.relu)\n",
        "    self.layer2 = tf.keras.layers.Dense(50, activation = tf.nn.relu)\n",
        "    # output layer\n",
        "    self.layer3 = tf.keras.layers.Dense(10, activation = tf.nn.softmax)\n",
        "  \n",
        "  # forward propagation of input matrix\n",
        "  def call(self, inputs):\n",
        "    flattened = self.flatten_layer(inputs)\n",
        "    hidden1 = self.layer1(flattened)\n",
        "    hidden2 = self.layer2(hidden1)\n",
        "    return self.layer3(hidden2)\n",
        "\n",
        "# collect data from keras database\n",
        "(train_images_rgb, train_labels), (test_images_rgb, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_images = []\n",
        "test_images = []\n",
        "\n",
        "# preprocessing images\n",
        "for image in train_images_rgb:\n",
        "  # convert RGB images to grayscale\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  new_image = []\n",
        "  for row in image:\n",
        "    # normalize grayscale values\n",
        "    row = row / 255\n",
        "    new_image.append(row)\n",
        "  train_images.append(new_image)\n",
        "\n",
        "for image in test_images_rgb:\n",
        "  image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "  new_image = []\n",
        "  for row in image:\n",
        "    row = row / 255\n",
        "    new_image.append(row)\n",
        "  test_images.append(new_image)\n",
        "\n",
        "# edit the shape of the image datasets\n",
        "train_images = tf.stack(train_images)\n",
        "test_images = tf.stack(test_images)\n",
        "\n",
        "# instantiate the models\n",
        "model1 = Model1()\n",
        "model2 = Model2()\n",
        "model3 = Model3()\n",
        "\n",
        "# define the optimizer and loss function for each model\n",
        "model1.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model2.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model3.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# train each model using the training images and labels\n",
        "# iterate through the whole dataset 20 times for each model\n",
        "model1.fit(train_images, train_labels, epochs = 20)\n",
        "print(\"Model 1 Trained\")\n",
        "model2.fit(train_images, train_labels, epochs = 20)\n",
        "print(\"Model 2 Trained\")\n",
        "model3.fit(train_images, train_labels, epochs = 20)\n",
        "print(\"Model 3 Trained\")\n",
        "\n",
        "# test each model using the testing images and labels, output the accuracy\n",
        "model1.evaluate(test_images, test_labels)\n",
        "model2.evaluate(test_images, test_labels)\n",
        "model3.evaluate(test_images, test_labels)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.2408 - accuracy: 0.1465\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.1424 - accuracy: 0.1895\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.1058 - accuracy: 0.2212\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0774 - accuracy: 0.2345\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0587 - accuracy: 0.2431\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0409 - accuracy: 0.2531\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0258 - accuracy: 0.2626\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 2.0116 - accuracy: 0.2668\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9985 - accuracy: 0.2698\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9952 - accuracy: 0.2702\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9818 - accuracy: 0.2829\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9777 - accuracy: 0.2807\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9803 - accuracy: 0.2802\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9703 - accuracy: 0.2840\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9702 - accuracy: 0.2847\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9660 - accuracy: 0.2903\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9624 - accuracy: 0.2892\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9604 - accuracy: 0.2902\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9547 - accuracy: 0.2954\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 3s 2ms/step - loss: 1.9563 - accuracy: 0.2952\n",
            "Model 1 Trained\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1263 - accuracy: 0.2247\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.9073 - accuracy: 0.3189\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.8197 - accuracy: 0.3497\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7686 - accuracy: 0.3699\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.7186 - accuracy: 0.3887\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6887 - accuracy: 0.4006\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6597 - accuracy: 0.4088\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6264 - accuracy: 0.4219\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6007 - accuracy: 0.4323\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5852 - accuracy: 0.4341\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5705 - accuracy: 0.4408\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5543 - accuracy: 0.4484\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5242 - accuracy: 0.4577\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5122 - accuracy: 0.4618\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4990 - accuracy: 0.4714\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4745 - accuracy: 0.4785\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4717 - accuracy: 0.4798\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4563 - accuracy: 0.4876\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.4503 - accuracy: 0.4858\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.4234 - accuracy: 0.4960\n",
            "Model 2 Trained\n",
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 2.1238 - accuracy: 0.2191\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.9162 - accuracy: 0.3072\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.8440 - accuracy: 0.3415\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7839 - accuracy: 0.3618\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7528 - accuracy: 0.3743\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7147 - accuracy: 0.3874\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.7100 - accuracy: 0.3938\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6949 - accuracy: 0.3939\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6648 - accuracy: 0.4121\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6592 - accuracy: 0.4083\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6452 - accuracy: 0.4175\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.6339 - accuracy: 0.4145\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6224 - accuracy: 0.4209\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6052 - accuracy: 0.4285\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.6018 - accuracy: 0.4281\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5818 - accuracy: 0.4307\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5810 - accuracy: 0.4341\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5758 - accuracy: 0.4402\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 5s 3ms/step - loss: 1.5652 - accuracy: 0.4447\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 4s 3ms/step - loss: 1.5553 - accuracy: 0.4468\n",
            "Model 3 Trained\n",
            "313/313 [==============================] - 1s 1ms/step - loss: 2.0122 - accuracy: 0.2680\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6055 - accuracy: 0.4338\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 1.6364 - accuracy: 0.4135\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6364028453826904, 0.41350001096725464]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlGtn_E5VzTX"
      },
      "source": [
        "# **Results**\n",
        "\n",
        "The baseline model had an accuracy of 0.2680 on the testing dataset. The first improved model had an accuracy of 0.4338 while the second had an accuracy of 0.4135. This was unexpected, as the ReLU activation function maintains the gradient, improving the model's ability to adapt to new training data.\n",
        "\n",
        "## Future Improvements\n",
        "\n",
        "The models can be improved by changing the number of hidden layers/neurons, changing the optimizer and loss functions, and increasing the amount of training data and time."
      ]
    }
  ]
}