{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phvIuf2G_-ip"
      },
      "source": [
        "#Project 4 - Sentiment Analysis using Logistic Regression\n",
        "Aman Patel\n",
        "\n",
        "CSCI-B 455\n",
        "\n",
        "April 11, 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x8lyq4rNATRI"
      },
      "source": [
        "#**Introduction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GTTsjcpvAcqZ"
      },
      "source": [
        "## Problem Statement\n",
        "The goal for this project was to create a Logistic Regression model using scikit-learn to predict the sentiment of movie reviews. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iq8vTYTiB3kN"
      },
      "source": [
        "## Data\n",
        "\n",
        "The dataset used for this project was collected from the Stanford University Artificial Intelligence department. It contained 50000 movie review samples, 25000 for training and 25000 for testing. The samples were tokenized and the frequency of each word was recorded. The data can be found at http://ai.stanford.edu/~amaas/data/sentiment/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unr3l8MUDfzM"
      },
      "source": [
        "## Model Parameters\n",
        "\n",
        "Most of the parameters used for the model were the default parameters from scikit-learn. Max-iter was increased to 500 to allow for convergence, multi-class was set to 'ovr' to perform binary classification, and C was lowered to 0.04 to increase the regularization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqtCs95LEsvA"
      },
      "source": [
        "# **Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yj9wlLl3Oyp8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a640d15-4b58-4398-8ce2-3226d75976a6"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction import DictVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# process provided feature file to convert to usable form\n",
        "file = open('labeledBow_train.feat')\n",
        "contents = file.readlines()\n",
        "file.close()\n",
        "train_labels = []\n",
        "train_dictionaries = []\n",
        "# convert each line of feat into a dictionary\n",
        "for string in contents:\n",
        "    dictionary = {}\n",
        "    stripped = string.rstrip('\\n')\n",
        "    split = stripped.split(' ')\n",
        "    train_labels.append(int(split[0]))\n",
        "    for i in range(1, len(split)):\n",
        "        kv = split[i].split(':')\n",
        "        key = int(kv[0])\n",
        "        value = int(kv[1])\n",
        "        dictionary[key] = value\n",
        "    train_dictionaries.append(dictionary)\n",
        "\n",
        "file = open('labeledBow_test.feat')\n",
        "contents = file.readlines()\n",
        "file.close()\n",
        "test_labels = []\n",
        "test_dictionaries = []\n",
        "for string in contents:\n",
        "    dictionary = {}\n",
        "    stripped = string.rstrip('\\n')\n",
        "    split = stripped.split(' ')\n",
        "    test_labels.append(int(split[0]))\n",
        "    for i in range(1, len(split)):\n",
        "        kv = split[i].split(':')\n",
        "        key = int(kv[0])\n",
        "        value = int(kv[1])\n",
        "        dictionary[key] = value\n",
        "    test_dictionaries.append(dictionary)\n",
        "\n",
        "# DictVectorizer converts array of dictionaries into sparse matrix\n",
        "vec1 = DictVectorizer()\n",
        "train_data = vec1.fit_transform(train_dictionaries)\n",
        "train_data.resize((train_data.shape[0], 89527))\n",
        "\n",
        "vec2 = DictVectorizer()\n",
        "test_data = vec2.fit_transform(test_dictionaries)\n",
        "test_data.resize((test_data.shape[0], 89527))\n",
        "\n",
        "# normalize the data\n",
        "train_data = StandardScaler(with_mean=False).fit_transform(train_data)\n",
        "test_data = StandardScaler(with_mean=False).fit_transform(test_data)\n",
        "\n",
        "# convert train and test labels to binary\n",
        "for i in range(len(train_labels)):\n",
        "  if train_labels[i] <= 5:\n",
        "    train_labels[i] = 0\n",
        "  else:\n",
        "    train_labels[i] = 1\n",
        "\n",
        "for i in range(len(test_labels)):\n",
        "  if test_labels[i] <= 5:\n",
        "    test_labels[i] = 0\n",
        "  else:\n",
        "    test_labels[i] = 1\n",
        "\n",
        "# Logistic regression model trained on sparse matrices\n",
        "model = LogisticRegression(random_state=0, multi_class='ovr',C=0.04).fit(train_data, train_labels)\n",
        "\n",
        "# 5-Fold Cross validation on test data\n",
        "scores = cross_val_score(model, test_data, test_labels, cv=5)\n",
        "print('Cross-Validation Accuracy Scores', scores)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cross-Validation Accuracy Scores [0.832  0.8308 0.846  0.8434 0.8508]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALsKxdw5Ey4T"
      },
      "source": [
        "# **Results**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2yvkuJ6E3Oa"
      },
      "source": [
        "The model had accuracy scores of:\n",
        "\n",
        "```\n",
        "[0.832  0.8308 0.846  0.8434 0.8508]\n",
        "```\n",
        "\n",
        "The model vastly outperforms the baseline accuracy of 50% (the number of negative reviews is equal to the number of positive reviews). To improve the model, the value for C (inverse regularization) can be decreased further. This would smooth the data and help prevent overfitting. Also, as with any model, adding more training data and training over more iterations will increase accuracy, given overfitting is held under control."
      ]
    }
  ]
}